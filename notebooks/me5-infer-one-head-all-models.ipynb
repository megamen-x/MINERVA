{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":122880,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":103422,"modelId":127646},{"sourceId":122945,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":103474,"modelId":127696}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport random\nimport pickle\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nfrom transformers import DataCollatorWithPadding\n%env TOKENIZERS_PARALLELISM=false\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-28T20:43:27.769909Z","iopub.execute_input":"2024-09-28T20:43:27.770308Z","iopub.status.idle":"2024-09-28T20:43:44.266449Z","shell.execute_reply.started":"2024-09-28T20:43:27.770267Z","shell.execute_reply":"2024-09-28T20:43:44.265481Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"env: TOKENIZERS_PARALLELISM=false\n","output_type":"stream"}]},{"cell_type":"code","source":"class CFG:\n    num_workers=8\n    path_11=\"/kaggle/input/me5_11_cls/pytorch/default/1/kaggle/working/me5_instruct_11_classes\"\n    path_39=\"/kaggle/input/me5_39_cls/pytorch/default/1/kaggle/working/me5_instruct_39_classes\"\n    config_path_11='/kaggle/input/me5_11_cls/pytorch/default/1/kaggle/working/me5_instruct_11_classes/config.pth'\n    config_path_39='/kaggle/input/me5_39_cls/pytorch/default/1/kaggle/working/me5_instruct_39_classes/config.pth'\n    model=\"intfloat/multilingual-e5-large-instruct\"\n    gradient_checkpointing=False\n    batch_size=32\n    seed=42\n    max_len=512\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:44.268470Z","iopub.execute_input":"2024-09-28T20:43:44.269199Z","iopub.status.idle":"2024-09-28T20:43:44.274604Z","shell.execute_reply.started":"2024-09-28T20:43:44.269153Z","shell.execute_reply":"2024-09-28T20:43:44.273531Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:44.275818Z","iopub.execute_input":"2024-09-28T20:43:44.276100Z","iopub.status.idle":"2024-09-28T20:43:44.298320Z","shell.execute_reply.started":"2024-09-28T20:43:44.276069Z","shell.execute_reply":"2024-09-28T20:43:44.297553Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# тут нужен препроцесс из трейна\ndef preprocess(text):\n    processed_text = \" \".join(re.findall(r\"[а-яА-Я0-9 ёЁ\\-\\.,?!+a-zA-Z]+\", text))\n    return processed_text\n\ndef get_detailed_instruct(task_description: str, query: str) -> str:\n    # функция преобразования промпта для instruct версий моделей\n    return f'Instruct: {task_description}\\nQuery: {query}'","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:44.300421Z","iopub.execute_input":"2024-09-28T20:43:44.300793Z","iopub.status.idle":"2024-09-28T20:43:44.306043Z","shell.execute_reply.started":"2024-09-28T20:43:44.300761Z","shell.execute_reply":"2024-09-28T20:43:44.305134Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def prepare_input(cfg, text):\n    inputs = cfg.tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True, \n        max_length=512,\n        pad_to_max_length=True,\n        truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, texts):\n        self.cfg = cfg\n        self.texts = texts if isinstance(texts, list) else [texts]\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:44.306960Z","iopub.execute_input":"2024-09-28T20:43:44.307251Z","iopub.status.idle":"2024-09-28T20:43:44.315591Z","shell.execute_reply.started":"2024-09-28T20:43:44.307220Z","shell.execute_reply":"2024-09-28T20:43:44.314691Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def average_pool(last_hidden_states, attention_mask):\n    last_hidden = last_hidden_states.masked_fill(\n        ~attention_mask[..., None].bool(), 0.0)\n    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n\n\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, num_classes, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(\n                cfg.model, output_hidden_states=True)\n            self.config.hidden_dropout = 0.\n            self.config.hidden_dropout_prob = 0.\n            self.config.attention_dropout = 0.\n            self.config.attention_probs_dropout_prob = 0.\n            LOGGER.info(self.config)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(\n                cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        if self.cfg.gradient_checkpointing:\n            self.model.gradient_checkpointing_enable()\n\n        self.fc = nn.Linear(self.config.hidden_size, num_classes)\n        self._init_weights(self.fc)\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(\n                mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(\n                mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n\n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        feature = average_pool(outputs.last_hidden_state,\n                               inputs['attention_mask'])\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(feature)\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:44.316819Z","iopub.execute_input":"2024-09-28T20:43:44.317251Z","iopub.status.idle":"2024-09-28T20:43:44.331779Z","shell.execute_reply.started":"2024-09-28T20:43:44.317203Z","shell.execute_reply":"2024-09-28T20:43:44.330926Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            pred = model(inputs)\n                \n        preds.append(pred.to('cpu').numpy())\n    \n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:44.332981Z","iopub.execute_input":"2024-09-28T20:43:44.333343Z","iopub.status.idle":"2024-09-28T20:43:44.342560Z","shell.execute_reply.started":"2024-09-28T20:43:44.333301Z","shell.execute_reply":"2024-09-28T20:43:44.341816Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"CFG.tokenizer = AutoTokenizer.from_pretrained(os.path.join(CFG.path_11, 'tokenizer'))","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:44.343604Z","iopub.execute_input":"2024-09-28T20:43:44.345813Z","iopub.status.idle":"2024-09-28T20:43:45.131226Z","shell.execute_reply.started":"2024-09-28T20:43:44.345780Z","shell.execute_reply":"2024-09-28T20:43:45.130408Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# сам пример запроса\nuser_query = \"Здравствуйте! Где я могу узнать про монетизацию RUTUBE?\"\nuser_query = preprocess(user_query)\nprint(user_query)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:45.132353Z","iopub.execute_input":"2024-09-28T20:43:45.132678Z","iopub.status.idle":"2024-09-28T20:43:45.138298Z","shell.execute_reply.started":"2024-09-28T20:43:45.132645Z","shell.execute_reply":"2024-09-28T20:43:45.137376Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Здравствуйте! Где я могу узнать про монетизацию RUTUBE?\n","output_type":"stream"}]},{"cell_type":"code","source":"user_queries = []\n\nif CFG.model in ['intfloat/multilingual-e5-large-instruct']:\n    task = \"\"\"Classify the detailed category of the given user request into one of {num_cats} categories\"\"\"\n    for num_cats in ['eleven', 'thirty nine']:\n        task_ = task.format(num_cats=num_cats)\n        user_queries.append(get_detailed_instruct(task_, user_query))\n    \nprint(user_queries[1])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:45.141286Z","iopub.execute_input":"2024-09-28T20:43:45.141642Z","iopub.status.idle":"2024-09-28T20:43:45.149006Z","shell.execute_reply.started":"2024-09-28T20:43:45.141609Z","shell.execute_reply":"2024-09-28T20:43:45.148050Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Instruct: Classify the detailed category of the given user request into one of thirty nine categories\nQuery: Здравствуйте! Где я могу узнать про монетизацию RUTUBE?\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset_11 = TestDataset(CFG, user_queries[0])\ntest_dataset_39 = TestDataset(CFG, user_queries[1])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:45.150090Z","iopub.execute_input":"2024-09-28T20:43:45.150384Z","iopub.status.idle":"2024-09-28T20:43:45.161945Z","shell.execute_reply.started":"2024-09-28T20:43:45.150340Z","shell.execute_reply":"2024-09-28T20:43:45.160954Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"test_loader_11 = DataLoader(\n    test_dataset_11,\n    batch_size=CFG.batch_size,\n    shuffle=False,\n    collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n    num_workers=CFG.num_workers, pin_memory=True, drop_last=False\n)\n\ntest_loader_39 = DataLoader(\n    test_dataset_39,\n    batch_size=CFG.batch_size,\n    shuffle=False,\n    collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n    num_workers=CFG.num_workers, pin_memory=True, drop_last=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:45.162870Z","iopub.execute_input":"2024-09-28T20:43:45.163145Z","iopub.status.idle":"2024-09-28T20:43:45.172938Z","shell.execute_reply.started":"2024-09-28T20:43:45.163115Z","shell.execute_reply":"2024-09-28T20:43:45.172131Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model_11 = CustomModel(CFG, num_classes=11, config_path=CFG.config_path_11, pretrained=False)\nstate_11 = torch.load(os.path.join(CFG.path_11, f\"{CFG.model.replace('/', '-')}_fold0_best.pth\"),\n                   map_location=torch.device('cpu'))\nmodel_11.load_state_dict(state_11['model'])\n\n\nmodel_39 = CustomModel(CFG, num_classes=39, config_path=CFG.config_path_39, pretrained=False)\nstate_39 = torch.load(os.path.join(CFG.path_39, f\"{CFG.model.replace('/', '-')}_fold0_best.pth\"),\n                   map_location=torch.device('cpu'))\nmodel_39.load_state_dict(state_39['model'])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:43:45.173879Z","iopub.execute_input":"2024-09-28T20:43:45.174161Z","iopub.status.idle":"2024-09-28T20:44:33.393236Z","shell.execute_reply.started":"2024-09-28T20:43:45.174132Z","shell.execute_reply":"2024-09-28T20:44:33.392216Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"predictions_11 = inference_fn(test_loader_11, model_11, device)\npredictions_39 = inference_fn(test_loader_39, model_39, device)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:44:33.394991Z","iopub.execute_input":"2024-09-28T20:44:33.395763Z","iopub.status.idle":"2024-09-28T20:44:38.447140Z","shell.execute_reply.started":"2024-09-28T20:44:33.395717Z","shell.execute_reply":"2024-09-28T20:44:38.445376Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a680d07fbbf84132acd6dc28a51a23e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a1cf083a2284ff8bbf7cf47a756fbfb"}},"metadata":{}}]},{"cell_type":"code","source":"final_labels_11 = [np.argmax(el) for el in predictions_11]\nfinal_labels_39 = [np.argmax(el) for el in predictions_39]","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:44:38.449264Z","iopub.execute_input":"2024-09-28T20:44:38.449670Z","iopub.status.idle":"2024-09-28T20:44:38.456362Z","shell.execute_reply.started":"2024-09-28T20:44:38.449620Z","shell.execute_reply":"2024-09-28T20:44:38.455412Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nwith open (\"/kaggle/input/me5_11_cls/pytorch/default/1/kaggle/working/me5_instruct_11_classes/executor_le.pkl\", \"rb\") as f:\n    exec_le_11 = pickle.load(f)\n    \nwith open (\"/kaggle/input/me5_39_cls/pytorch/default/1/kaggle/working/me5_instruct_39_classes/executor_le.pkl\", \"rb\") as f:\n    exec_le_39 = pickle.load(f)\n\nle_final_labels_11 = exec_le_11.inverse_transform(final_labels_11)\nle_final_labels_39 = exec_le_39.inverse_transform(final_labels_39)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:44:38.457531Z","iopub.execute_input":"2024-09-28T20:44:38.457860Z","iopub.status.idle":"2024-09-28T20:44:38.479821Z","shell.execute_reply.started":"2024-09-28T20:44:38.457829Z","shell.execute_reply":"2024-09-28T20:44:38.478819Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"le_final_labels_11","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:44:38.480926Z","iopub.execute_input":"2024-09-28T20:44:38.481349Z","iopub.status.idle":"2024-09-28T20:44:38.487709Z","shell.execute_reply.started":"2024-09-28T20:44:38.481317Z","shell.execute_reply":"2024-09-28T20:44:38.486912Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array(['МОНЕТИЗАЦИЯ'], dtype='<U34')"},"metadata":{}}]},{"cell_type":"code","source":"le_final_labels_39","metadata":{"execution":{"iopub.status.busy":"2024-09-28T20:44:38.488872Z","iopub.execute_input":"2024-09-28T20:44:38.489322Z","iopub.status.idle":"2024-09-28T20:44:38.498508Z","shell.execute_reply.started":"2024-09-28T20:44:38.489277Z","shell.execute_reply":"2024-09-28T20:44:38.497539Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array(['Отключение/подключение монетизации'], dtype='<U38')"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}